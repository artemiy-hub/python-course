# –¢–µ–æ—Ä–∏—è: –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤ Python

## üéØ –¶–µ–ª—å —Ä–∞–∑–¥–µ–ª–∞

–≠—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏ –≤ Python: –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ –¥–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ç–µ—Ö–Ω–∏–∫, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π.

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û—Å–Ω–æ–≤—ã —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π](#–æ—Å–Ω–æ–≤—ã-—Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö-–≤—ã—Ä–∞–∂–µ–Ω–∏–π)
2. [–ú–µ—Ç–∞—Å–∏–º–≤–æ–ª—ã –∏ –∫–≤–∞–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã](#–º–µ—Ç–∞—Å–∏–º–≤–æ–ª—ã-–∏-–∫–≤–∞–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã)
3. [–ì—Ä—É–ø–ø—ã –∏ –∑–∞—Ö–≤–∞—Ç](#–≥—Ä—É–ø–ø—ã-–∏-–∑–∞—Ö–≤–∞—Ç)
4. [–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏](#–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ-—Ç–µ—Ö–Ω–∏–∫–∏)
5. [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è](#–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ-–ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è)
6. [–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏](#–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
7. [–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã regex](#–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã-regex)

---

## üé≠ –û—Å–Ω–æ–≤—ã —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π

–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è - –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º.

### –ë–∞–∑–æ–≤—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –∏ –º–æ–¥—É–ª—å re

```python
import re
from typing import List, Dict, Optional, Union, Iterator, Tuple, Any
import time
from dataclasses import dataclass
from enum import Enum
import functools

class RegexPatterns:
    """–ö–æ–ª–ª–µ–∫—Ü–∏—è –ø–æ–ª–µ–∑–Ω—ã—Ö —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    EMAIL = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    PHONE_RU = r'(?:\+7|8)[-.\s]?\(?(?:9\d{2}|[1-6]\d{2}|7[0-9][0-9])\)?[-.\s]?\d{3}[-.\s]?\d{2}[-.\s]?\d{2}'
    URL = r'https?://(?:[-\w.])+(?:\:[0-9]+)?(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:\#(?:[\w.])*)?)?'
    IPV4 = r'(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)'
    IPV6 = r'(?:[0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}'
    
    # –§–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö
    DATE_ISO = r'\d{4}-\d{2}-\d{2}'
    DATE_US = r'\d{1,2}/\d{1,2}/\d{4}'
    DATE_EU = r'\d{1,2}\.\d{1,2}\.\d{4}'
    TIME_24H = r'(?:[01]\d|2[0-3]):[0-5]\d(?::[0-5]\d)?'
    
    # –§–∏–Ω–∞–Ω—Å—ã
    PRICE = r'\$?\d{1,3}(?:,\d{3})*(?:\.\d{2})?'
    CREDIT_CARD = r'\b(?:\d{4}[-.\s]?){3}\d{4}\b'
    
    # –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
    PYTHON_VARIABLE = r'\b[a-zA-Z_][a-zA-Z0-9_]*\b'
    HEX_COLOR = r'#(?:[0-9a-fA-F]{3}){1,2}\b'
    
    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    SQL_INJECTION = r'(?i)(union|select|insert|update|delete|drop|create|alter|exec|execute)\s'
    XSS_BASIC = r'<script[^>]*>.*?</script>'

@dataclass
class RegexMatch:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
    text: str
    start: int
    end: int
    groups: List[str]
    named_groups: Dict[str, str]
    pattern: str

class RegexEngine:
    """–î–≤–∏–∂–æ–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏"""
    
    def __init__(self, case_sensitive: bool = True, multiline: bool = False, 
                 dotall: bool = False, unicode: bool = True):
        self.flags = 0
        
        if not case_sensitive:
            self.flags |= re.IGNORECASE
        if multiline:
            self.flags |= re.MULTILINE
        if dotall:
            self.flags |= re.DOTALL
        if unicode:
            self.flags |= re.UNICODE
        
        self._compiled_patterns = {}
    
    def compile_pattern(self, pattern: str) -> re.Pattern:
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        if pattern not in self._compiled_patterns:
            self._compiled_patterns[pattern] = re.compile(pattern, self.flags)
        return self._compiled_patterns[pattern]
    
    def search(self, pattern: str, text: str) -> Optional[RegexMatch]:
        """–ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        compiled_pattern = self.compile_pattern(pattern)
        match = compiled_pattern.search(text)
        
        if match:
            return RegexMatch(
                text=match.group(0),
                start=match.start(),
                end=match.end(),
                groups=list(match.groups()),
                named_groups=match.groupdict(),
                pattern=pattern
            )
        return None
    
    def find_all(self, pattern: str, text: str) -> List[RegexMatch]:
        """–ü–æ–∏—Å–∫ –≤—Å–µ—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""
        compiled_pattern = self.compile_pattern(pattern)
        matches = []
        
        for match in compiled_pattern.finditer(text):
            matches.append(RegexMatch(
                text=match.group(0),
                start=match.start(),
                end=match.end(),
                groups=list(match.groups()),
                named_groups=match.groupdict(),
                pattern=pattern
            ))
        
        return matches
    
    def substitute(self, pattern: str, replacement: str, text: str, 
                  count: int = 0) -> Tuple[str, int]:
        """–ó–∞–º–µ–Ω–∞ —Å –ø–æ–¥—Å—á–µ—Ç–æ–º"""
        compiled_pattern = self.compile_pattern(pattern)
        result = compiled_pattern.subn(replacement, text, count=count)
        return result
    
    def split(self, pattern: str, text: str, max_split: int = 0) -> List[str]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
        compiled_pattern = self.compile_pattern(pattern)
        return compiled_pattern.split(text, maxsplit=max_split)
    
    def match_full(self, pattern: str, text: str) -> Optional[RegexMatch]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        compiled_pattern = self.compile_pattern(pattern)
        match = compiled_pattern.fullmatch(text)
        
        if match:
            return RegexMatch(
                text=match.group(0),
                start=match.start(),
                end=match.end(),
                groups=list(match.groups()),
                named_groups=match.groupdict(),
                pattern=pattern
            )
        return None

class TextValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self):
        self.engine = RegexEngine()
        self.validation_rules = {}
    
    def add_rule(self, name: str, pattern: str, description: str = "",
                error_message: str = "–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        self.validation_rules[name] = {
            'pattern': pattern,
            'description': description,
            'error_message': error_message
        }
    
    def validate(self, rule_name: str, text: str) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –ø—Ä–∞–≤–∏–ª—É"""
        if rule_name not in self.validation_rules:
            return {
                'valid': False,
                'error': f"–ü—Ä–∞–≤–∏–ª–æ '{rule_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            }
        
        rule = self.validation_rules[rule_name]
        match = self.engine.match_full(rule['pattern'], text)
        
        return {
            'valid': match is not None,
            'error': None if match else rule['error_message'],
            'match': match
        }
    
    def validate_multiple(self, rules: List[str], text: str) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø—Ä–∞–≤–∏–ª–∞–º"""
        results = {}
        all_valid = True
        
        for rule_name in rules:
            result = self.validate(rule_name, text)
            results[rule_name] = result
            
            if not result['valid']:
                all_valid = False
        
        return {
            'all_valid': all_valid,
            'results': results
        }

# –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
def setup_common_validators() -> TextValidator:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—â–∏—Ö –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–æ–≤"""
    validator = TextValidator()
    
    # Email
    validator.add_rule(
        'email',
        RegexPatterns.EMAIL,
        '–ü—Ä–æ–≤–µ—Ä–∫–∞ email –∞–¥—Ä–µ—Å–∞',
        '–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π email –∞–¥—Ä–µ—Å'
    )
    
    # –†–æ—Å—Å–∏–π—Å–∫–∏–π —Ç–µ–ª–µ—Ñ–æ–Ω
    validator.add_rule(
        'phone_ru',
        RegexPatterns.PHONE_RU,
        '–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞',
        '–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞'
    )
    
    # URL
    validator.add_rule(
        'url',
        RegexPatterns.URL,
        '–ü—Ä–æ–≤–µ—Ä–∫–∞ URL',
        '–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL'
    )
    
    # –ü–∞—Ä–æ–ª—å (–º–∏–Ω–∏–º—É–º 8 —Å–∏–º–≤–æ–ª–æ–≤, –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã)
    validator.add_rule(
        'password_basic',
        r'^(?=.*[A-Za-z])(?=.*\d)[A-Za-z\d@$!%*#?&]{8,}$',
        '–ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–æ–ª—è',
        '–ü–∞—Ä–æ–ª—å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 8 —Å–∏–º–≤–æ–ª–æ–≤, –≤–∫–ª—é—á–∞—è –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã'
    )
    
    # –°–∏–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å
    validator.add_rule(
        'password_strong',
        r'^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)(?=.*[@$!%*?&])[A-Za-z\d@$!%*?&]{12,}$',
        '–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–ª—å–Ω–æ–≥–æ –ø–∞—Ä–æ–ª—è',
        '–ü–∞—Ä–æ–ª—å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 12 —Å–∏–º–≤–æ–ª–æ–≤: —Å—Ç—Ä–æ—á–Ω—ã–µ, –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã'
    )
    
    # –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    validator.add_rule(
        'username',
        r'^[a-zA-Z0-9_]{3,20}$',
        '–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è',
        '–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å 3-20 —Å–∏–º–≤–æ–ª–æ–≤ (–±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ)'
    )
    
    # –†–æ—Å—Å–∏–π—Å–∫–∏–π –ò–ù–ù
    validator.add_rule(
        'inn_ru',
        r'^\d{10}$|^\d{12}$',
        '–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –ò–ù–ù',
        '–ò–ù–ù –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä'
    )
    
    return validator

# –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏
class AdvancedRegexTechniques:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏"""
    
    @staticmethod
    def lookahead_lookbehind_examples():
        """–ü—Ä–∏–º–µ—Ä—ã look-ahead –∏ look-behind"""
        examples = {}
        
        # Positive lookahead - –Ω–∞–π—Ç–∏ —Å–ª–æ–≤–æ, –∑–∞ –∫–æ—Ç–æ—Ä—ã–º —Å–ª–µ–¥—É–µ—Ç –¥—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ
        text = "Python is great, Java is good, JavaScript is popular"
        pattern = r'\w+(?=\s+is)'  # –°–ª–æ–≤–∞ –ø–µ—Ä–µ–¥ "is"
        examples['positive_lookahead'] = {
            'pattern': pattern,
            'text': text,
            'matches': re.findall(pattern, text)
        }
        
        # Negative lookahead - –Ω–∞–π—Ç–∏ —Å–ª–æ–≤–æ, –∑–∞ –∫–æ—Ç–æ—Ä—ã–º –ù–ï —Å–ª–µ–¥—É–µ—Ç –¥—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ
        pattern = r'\w+(?!\s+is)'  # –°–ª–æ–≤–∞ –ù–ï –ø–µ—Ä–µ–¥ "is"
        examples['negative_lookahead'] = {
            'pattern': pattern,
            'text': text,
            'matches': re.findall(pattern, text)
        }
        
        # Positive lookbehind - –Ω–∞–π—Ç–∏ —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É–µ—Ç –¥—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ
        pattern = r'(?<=is\s)\w+'  # –°–ª–æ–≤–∞ –ø–æ—Å–ª–µ "is"
        examples['positive_lookbehind'] = {
            'pattern': pattern,
            'text': text,
            'matches': re.findall(pattern, text)
        }
        
        # Negative lookbehind - –Ω–∞–π—Ç–∏ —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–º—É –ù–ï –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É–µ—Ç –¥—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ
        pattern = r'(?<!is\s)\w+'  # –°–ª–æ–≤–∞ –ù–ï –ø–æ—Å–ª–µ "is"
        examples['negative_lookbehind'] = {
            'pattern': pattern,
            'text': text,
            'matches': re.findall(pattern, text)
        }
        
        return examples
    
    @staticmethod
    def greedy_vs_lazy():
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∂–∞–¥–Ω–æ–≥–æ –∏ –ª–µ–Ω–∏–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        text = '<div>content1</div><div>content2</div>'
        
        # –ñ–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫
        greedy_pattern = r'<div>.*</div>'
        greedy_match = re.search(greedy_pattern, text)
        
        # –õ–µ–Ω–∏–≤—ã–π –ø–æ–∏—Å–∫
        lazy_pattern = r'<div>.*?</div>'
        lazy_matches = re.findall(lazy_pattern, text)
        
        return {
            'text': text,
            'greedy': {
                'pattern': greedy_pattern,
                'result': greedy_match.group(0) if greedy_match else None
            },
            'lazy': {
                'pattern': lazy_pattern,
                'results': lazy_matches
            }
        }
    
    @staticmethod
    def named_groups_example():
        """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø"""
        text = "–î–∞—Ç–∞: 2024-01-15, –í—Ä–µ–º—è: 14:30:00"
        pattern = r'–î–∞—Ç–∞: (?P<date>\d{4}-\d{2}-\d{2}), –í—Ä–µ–º—è: (?P<time>\d{2}:\d{2}:\d{2})'
        
        match = re.search(pattern, text)
        
        if match:
            return {
                'pattern': pattern,
                'text': text,
                'full_match': match.group(0),
                'date': match.group('date'),
                'time': match.group('time'),
                'all_groups': match.groupdict()
            }
        
        return None
    
    @staticmethod
    def conditional_patterns():
        """–£—Å–ª–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —Å –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º –∫–æ–¥–æ–º –∏–ª–∏ –±–µ–∑
        pattern = r'(?P<country>\+\d{1,3}[-.\s]?)?(?P<area>\(?\d{3}\)?[-.\s]?)(?P<number>\d{3}[-.\s]?\d{4})'
        
        test_numbers = [
            "+7 (495) 123-4567",
            "495 123-4567",
            "+1-555-123-4567",
            "123-4567"
        ]
        
        results = []
        for number in test_numbers:
            match = re.search(pattern, number)
            if match:
                results.append({
                    'number': number,
                    'groups': match.groupdict(),
                    'has_country': bool(match.group('country'))
                })
        
        return {
            'pattern': pattern,
            'results': results
        }

class TextProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self):
        self.engine = RegexEngine()
    
    def extract_emails(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ email –∞–¥—Ä–µ—Å–æ–≤"""
        matches = self.engine.find_all(RegexPatterns.EMAIL, text)
        return [match.text for match in matches]
    
    def extract_phones(self, text: str, country: str = 'ru') -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–æ–≤ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"""
        if country == 'ru':
            pattern = RegexPatterns.PHONE_RU
        else:
            # –û–±—â–∏–π –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            pattern = r'\+?[1-9]\d{1,14}'
        
        matches = self.engine.find_all(pattern, text)
        return [match.text for match in matches]
    
    def extract_urls(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL"""
        matches = self.engine.find_all(RegexPatterns.URL, text)
        return [match.text for match in matches]
    
    def extract_dates(self, text: str, format_type: str = 'iso') -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç"""
        patterns = {
            'iso': RegexPatterns.DATE_ISO,
            'us': RegexPatterns.DATE_US,
            'eu': RegexPatterns.DATE_EU
        }
        
        pattern = patterns.get(format_type, RegexPatterns.DATE_ISO)
        matches = self.engine.find_all(pattern, text)
        return [match.text for match in matches]
    
    def clean_html(self, text: str) -> str:
        """–£–¥–∞–ª–µ–Ω–∏–µ HTML —Ç–µ–≥–æ–≤"""
        # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é
        text = re.sub(r'<(script|style)[^>]*>.*?</\1>', '', text, flags=re.DOTALL | re.IGNORECASE)
        
        # –£–¥–∞–ª—è–µ–º –æ–±—ã—á–Ω—ã–µ HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', text)
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML entities
        html_entities = {
            '&amp;': '&',
            '&lt;': '<',
            '&gt;': '>',
            '&quot;': '"',
            '&#39;': "'",
            '&nbsp;': ' '
        }
        
        for entity, char in html_entities.items():
            text = text.replace(entity, char)
        
        return text.strip()
    
    def normalize_whitespace(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤"""
        # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –æ–¥–Ω–∏–º
        text = re.sub(r'\s+', ' ', text)
        
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        text = re.sub(r'^\s+|\s+$', '', text, flags=re.MULTILINE)
        
        return text
    
    def extract_mentions(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (@username)"""
        pattern = r'@([a-zA-Z0-9_]+)'
        matches = self.engine.find_all(pattern, text)
        return [match.groups[0] for match in matches]
    
    def extract_hashtags(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–µ—à—Ç–µ–≥–æ–≤"""
        pattern = r'#([a-zA-Z0-9_]+)'
        matches = self.engine.find_all(pattern, text)
        return [match.groups[0] for match in matches]
    
    def mask_sensitive_data(self, text: str) -> str:
        """–ú–∞—Å–∫–∏—Ä–æ–≤–∫–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ú–∞—Å–∫–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä–∞ –∫–∞—Ä—Ç
        text = re.sub(RegexPatterns.CREDIT_CARD, 
                     lambda m: m.group(0)[:4] + '*' * (len(m.group(0)) - 8) + m.group(0)[-4:], 
                     text)
        
        # –ú–∞—Å–∫–∏—Ä—É–µ–º email (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é –±—É–∫–≤—É –∏ –¥–æ–º–µ–Ω)
        text = re.sub(RegexPatterns.EMAIL,
                     lambda m: m.group(0)[0] + '*' * (m.group(0).find('@') - 1) + m.group(0)[m.group(0).find('@'):],
                     text)
        
        # –ú–∞—Å–∫–∏—Ä—É–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã
        text = re.sub(RegexPatterns.PHONE_RU,
                     lambda m: m.group(0)[:3] + '*' * (len(re.sub(r'[^\d]', '', m.group(0))) - 6) + m.group(0)[-3:],
                     text)
        
        return text

class RegexPerformanceAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self):
        self.results = {}
    
    def benchmark_pattern(self, pattern: str, text: str, iterations: int = 1000) -> Dict[str, Any]:
        """–ë–µ–Ω—á–º–∞—Ä–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        # –¢–µ—Å—Ç –±–µ–∑ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏
        start_time = time.time()
        for _ in range(iterations):
            re.search(pattern, text)
        uncompiled_time = time.time() - start_time
        
        # –¢–µ—Å—Ç —Å –∫–æ–º–ø–∏–ª—è—Ü–∏–µ–π
        compiled_pattern = re.compile(pattern)
        start_time = time.time()
        for _ in range(iterations):
            compiled_pattern.search(text)
        compiled_time = time.time() - start_time
        
        # –¢–µ—Å—Ç findall
        start_time = time.time()
        for _ in range(iterations // 10):  # –ú–µ–Ω—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è findall
            compiled_pattern.findall(text)
        findall_time = (time.time() - start_time) * 10  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        
        return {
            'pattern': pattern,
            'text_length': len(text),
            'iterations': iterations,
            'uncompiled_time': uncompiled_time,
            'compiled_time': compiled_time,
            'findall_time': findall_time,
            'speedup_compilation': uncompiled_time / compiled_time if compiled_time > 0 else 0,
            'matches_found': len(compiled_pattern.findall(text))
        }
    
    def compare_patterns(self, patterns: List[str], text: str) -> Dict[str, Any]:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        results = {}
        
        for i, pattern in enumerate(patterns):
            try:
                result = self.benchmark_pattern(pattern, text)
                results[f'pattern_{i}'] = result
            except re.error as e:
                results[f'pattern_{i}'] = {
                    'pattern': pattern,
                    'error': str(e)
                }
        
        return results
    
    def analyze_complexity(self, pattern: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        analysis = {
            'pattern': pattern,
            'length': len(pattern),
            'metacharacters': 0,
            'quantifiers': 0,
            'groups': 0,
            'character_classes': 0,
            'anchors': 0,
            'lookarounds': 0,
            'complexity_score': 0
        }
        
        # –ü–æ–¥—Å—á–µ—Ç –º–µ—Ç–∞—Å–∏–º–≤–æ–ª–æ–≤
        metacharacters = r'\.^$*+?{}[]|()'
        analysis['metacharacters'] = sum(1 for char in pattern if char in metacharacters)
        
        # –ü–æ–¥—Å—á–µ—Ç –∫–≤–∞–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        quantifiers = ['*', '+', '?', '{']
        analysis['quantifiers'] = sum(1 for char in pattern if char in quantifiers)
        
        # –ü–æ–¥—Å—á–µ—Ç –≥—Ä—É–ø–ø
        analysis['groups'] = pattern.count('(')
        
        # –ü–æ–¥—Å—á–µ—Ç —Å–∏–º–≤–æ–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        analysis['character_classes'] = pattern.count('[')
        
        # –ü–æ–¥—Å—á–µ—Ç —è–∫–æ—Ä–µ–π
        anchors = ['^', '$', r'\b', r'\B']
        analysis['anchors'] = sum(pattern.count(anchor) for anchor in anchors)
        
        # –ü–æ–¥—Å—á–µ—Ç lookaround
        lookarounds = ['(?=', '(?!', '(?<=', '(?<!']
        analysis['lookarounds'] = sum(pattern.count(look) for look in lookarounds)
        
        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        analysis['complexity_score'] = (
            analysis['metacharacters'] +
            analysis['quantifiers'] * 2 +
            analysis['groups'] * 1.5 +
            analysis['character_classes'] * 1.2 +
            analysis['anchors'] * 0.5 +
            analysis['lookarounds'] * 3
        )
        
        return analysis

class RegexDebugger:
    """–û—Ç–ª–∞–¥—á–∏–∫ —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self):
        self.debug_info = {}
    
    def explain_pattern(self, pattern: str) -> Dict[str, Any]:
        """–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        explanation = {
            'pattern': pattern,
            'components': [],
            'flags': [],
            'groups': []
        }
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–±–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)
        i = 0
        while i < len(pattern):
            char = pattern[i]
            
            if char == '\\' and i + 1 < len(pattern):
                next_char = pattern[i + 1]
                if next_char == 'd':
                    explanation['components'].append({
                        'position': i,
                        'pattern': '\\d',
                        'meaning': '–õ—é–±–∞—è —Ü–∏—Ñ—Ä–∞ (0-9)'
                    })
                elif next_char == 'w':
                    explanation['components'].append({
                        'position': i,
                        'pattern': '\\w',
                        'meaning': '–õ—é–±–æ–π –±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤–æ–π —Å–∏–º–≤–æ–ª'
                    })
                elif next_char == 's':
                    explanation['components'].append({
                        'position': i,
                        'pattern': '\\s',
                        'meaning': '–õ—é–±–æ–π –ø—Ä–æ–±–µ–ª—å–Ω—ã–π —Å–∏–º–≤–æ–ª'
                    })
                i += 2
            
            elif char == '.':
                explanation['components'].append({
                    'position': i,
                    'pattern': '.',
                    'meaning': '–õ—é–±–æ–π —Å–∏–º–≤–æ–ª –∫—Ä–æ–º–µ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏'
                })
                i += 1
            
            elif char == '*':
                explanation['components'].append({
                    'position': i,
                    'pattern': '*',
                    'meaning': '–ù–æ–ª—å –∏–ª–∏ –±–æ–ª—å—à–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞'
                })
                i += 1
            
            elif char == '+':
                explanation['components'].append({
                    'position': i,
                    'pattern': '+',
                    'meaning': '–û–¥–∏–Ω –∏–ª–∏ –±–æ–ª—å—à–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞'
                })
                i += 1
            
            elif char == '?':
                explanation['components'].append({
                    'position': i,
                    'pattern': '?',
                    'meaning': '–ù–æ–ª—å –∏–ª–∏ –æ–¥–Ω–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞'
                })
                i += 1
            
            elif char == '^':
                explanation['components'].append({
                    'position': i,
                    'pattern': '^',
                    'meaning': '–ù–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏'
                })
                i += 1
            
            elif char == '$':
                explanation['components'].append({
                    'position': i,
                    'pattern': '$',
                    'meaning': '–ö–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏'
                })
                i += 1
            
            else:
                i += 1
        
        return explanation
    
    def test_pattern(self, pattern: str, test_strings: List[str]) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å—Ç—Ä–æ–∫"""
        results = {
            'pattern': pattern,
            'tests': []
        }
        
        try:
            compiled_pattern = re.compile(pattern)
            
            for test_string in test_strings:
                match = compiled_pattern.search(test_string)
                
                test_result = {
                    'string': test_string,
                    'matches': match is not None,
                    'match_text': match.group(0) if match else None,
                    'match_groups': list(match.groups()) if match else [],
                    'match_position': (match.start(), match.end()) if match else None
                }
                
                results['tests'].append(test_result)
                
        except re.error as e:
            results['error'] = str(e)
        
        return results

def demonstrate_regex_capabilities():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    print("üé≠ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    engine = RegexEngine(case_sensitive=False)
    validator = setup_common_validators()
    processor = TextProcessor()
    analyzer = RegexPerformanceAnalyzer()
    debugger = RegexDebugger()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
    test_text = """
    –ö–æ–Ω—Ç–∞–∫—Ç—ã:
    Email: john.doe@example.com, admin@site.ru
    –¢–µ–ª–µ—Ñ–æ–Ω: +7 (495) 123-45-67, 8-800-555-35-35
    –°–∞–π—Ç: https://example.com/page?id=123
    –î–∞—Ç–∞ –≤—Å—Ç—Ä–µ—á–∏: 2024-01-15
    –í—Ä–µ–º—è: 14:30:00
    
    #python #regex @developer
    """
    
    print("\nüìß –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ email:")
    emails = processor.extract_emails(test_text)
    for email in emails:
        print(f"  ‚Ä¢ {email}")
    
    print("\nüìû –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã:")
    phones = processor.extract_phones(test_text)
    for phone in phones:
        print(f"  ‚Ä¢ {phone}")
    
    print("\nüåê –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ URL:")
    urls = processor.extract_urls(test_text)
    for url in urls:
        print(f"  ‚Ä¢ {url}")
    
    print("\nüìÖ –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã:")
    dates = processor.extract_dates(test_text)
    for date in dates:
        print(f"  ‚Ä¢ {date}")
    
    print("\n#Ô∏è‚É£ –•–µ—à—Ç–µ–≥–∏ –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è:")
    hashtags = processor.extract_hashtags(test_text)
    mentions = processor.extract_mentions(test_text)
    print(f"  –•–µ—à—Ç–µ–≥–∏: {hashtags}")
    print(f"  –£–ø–æ–º–∏–Ω–∞–Ω–∏—è: {mentions}")
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    print("\n‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö:")
    test_cases = [
        ('email', 'user@example.com'),
        ('email', 'invalid-email'),
        ('password_strong', 'MyPass123!@#'),
        ('password_strong', '123456'),
    ]
    
    for rule, test_value in test_cases:
        result = validator.validate(rule, test_value)
        status = "‚úÖ" if result['valid'] else "‚ùå"
        print(f"  {status} {rule}: '{test_value}' - {result.get('error', 'OK')}")
    
    # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏
    print("\nüîç –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:")
    lookahead_examples = AdvancedRegexTechniques.lookahead_lookbehind_examples()
    print(f"  Positive lookahead –Ω–∞–π–¥–µ–Ω–æ: {len(lookahead_examples['positive_lookahead']['matches'])} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
    
    greedy_lazy = AdvancedRegexTechniques.greedy_vs_lazy()
    print(f"  –ñ–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫: {len(greedy_lazy['greedy']['result']) if greedy_lazy['greedy']['result'] else 0} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  –õ–µ–Ω–∏–≤—ã–π –ø–æ–∏—Å–∫: {len(greedy_lazy['lazy']['results'])} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    print("\n‚ö° –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
    performance = analyzer.benchmark_pattern(RegexPatterns.EMAIL, test_text * 100)
    print(f"  –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ—Ç –∫–æ–º–ø–∏–ª—è—Ü–∏–∏: {performance['speedup_compilation']:.2f}x")
    print(f"  –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {performance['matches_found']}")
    
    return {
        'emails': emails,
        'phones': phones,
        'urls': urls,
        'dates': dates,
        'hashtags': hashtags,
        'mentions': mentions,
        'performance': performance
    }

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º
class RegexAlternatives:
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á"""
    
    @staticmethod
    def parse_csv_simple(text: str) -> List[List[str]]:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä CSV –±–µ–∑ regex"""
        import csv
        import io
        
        reader = csv.reader(io.StringIO(text))
        return list(reader)
    
    @staticmethod
    def extract_urls_simple(text: str) -> List[str]:
        """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ URL –±–µ–∑ regex"""
        urls = []
        words = text.split()
        
        for word in words:
            if word.startswith(('http://', 'https://', 'www.')):
                # –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ
                url = word.rstrip('.,!?;')
                urls.append(url)
        
        return urls
    
    @staticmethod
    def validate_email_simple(email: str) -> bool:
        """–ü—Ä–æ—Å—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è email –±–µ–∑ regex"""
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if email.count('@') != 1:
            return False
        
        local, domain = email.split('@')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–∏
        if not local or len(local) > 64:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–º–µ–Ω–∞
        if not domain or '.' not in domain:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
        allowed_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.-_')
        
        if not all(c in allowed_chars for c in email):
            return False
        
        return True
    
    @staticmethod
    def performance_comparison():
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ regex vs –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤"""
        test_text = "Contact us at: admin@example.com, support@test.org, or visit https://example.com"
        
        # –¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è URL
        iterations = 10000
        
        # Regex –º–µ—Ç–æ–¥
        start_time = time.time()
        for _ in range(iterations):
            re.findall(RegexPatterns.URL, test_text)
        regex_time = time.time() - start_time
        
        # –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥
        start_time = time.time()
        for _ in range(iterations):
            RegexAlternatives.extract_urls_simple(test_text)
        simple_time = time.time() - start_time
        
        return {
            'regex_time': regex_time,
            'simple_time': simple_time,
            'speedup': regex_time / simple_time if simple_time > 0 else 0
        }

if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    results = demonstrate_regex_capabilities()
    
    print("\nüîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏:")
    comparison = RegexAlternatives.performance_comparison()
    print(f"  Regex –≤—Ä–µ–º—è: {comparison['regex_time']:.4f}s")
    print(f"  –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥: {comparison['simple_time']:.4f}s")
    
    if comparison['speedup'] > 1:
        print(f"  –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –±—ã—Å—Ç—Ä–µ–µ –≤ {comparison['speedup']:.2f} —Ä–∞–∑")
    else:
        print(f"  Regex –±—ã—Å—Ç—Ä–µ–µ –≤ {1/comparison['speedup']:.2f} —Ä–∞–∑") 